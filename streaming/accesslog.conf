# Require hadoop command in PATH
# To run: $ bin/flume-ng agent --conf conf --conf-file apachelog.conf --name a1 -Dflume.root.logger=INFO,console &

# Define agent name "a1"
a1.sources = sr1
a1.sinks = sk1
a1.channels = ch1

# Define tail -F source
a1.sources.sr1.type = exec
a1.sources.sr1.command = tail -F /tmp/access.log
a1.sources.sr1.restart = true
a1.sources.sr1.channels = ch1

# Define spark sink as a server on port 5000
a1.sinks.sk1.type =  org.apache.spark.streaming.flume.sink.SparkSink
a1.sinks.sk1.hostname = spark-master
a1.sinks.sk1.port = 5000
a1.sinks.sk1.channel = ch1

# Define memory channel
a1.channels.ch1.type = memory

